{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import LoadJobConfig\n",
    "from google.cloud.bigquery import SchemaField\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \".google_application_credentials.json\"\n",
    "\n",
    "def upload_to_bigquery(df, table_id, schema=None, table_description=None):\n",
    "    \"\"\"\n",
    "    Upload a DataFrame to BigQuery. If table exists, append to it.\n",
    "    If table doesn't exist, create it with the provided schema.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame containing the data to upload\n",
    "        table_id: str, full path to BigQuery table (project.dataset.table)\n",
    "        schema: list of SchemaField objects defining the table schema.\n",
    "               Required only when creating a new table.\n",
    "        table_description: str, description of the table contents and usage.\n",
    "                         Used only when creating a new table.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client()\n",
    "    \n",
    "    # Check if table exists\n",
    "    try:\n",
    "        table = client.get_table(table_id)\n",
    "        table_exists = True\n",
    "    except Exception:\n",
    "        table_exists = False\n",
    "        \n",
    "    # Configure load job\n",
    "    job_config = LoadJobConfig()\n",
    "    \n",
    "    if table_exists:\n",
    "        # Append mode for existing table\n",
    "        job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "        job_config.schema = table.schema\n",
    "    else:\n",
    "        # Create new table\n",
    "        if schema is None:\n",
    "            raise ValueError(\"Schema must be provided when creating a new table\")\n",
    "            \n",
    "        job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "        job_config.schema = schema\n",
    "        \n",
    "        # Create table with schema and description\n",
    "        table = bigquery.Table(table_id, schema=schema)\n",
    "        if table_description:\n",
    "            table.description = table_description\n",
    "        table = client.create_table(table, exists_ok=True)\n",
    "\n",
    "    # Load data from DataFrame\n",
    "    job = client.load_table_from_dataframe(\n",
    "        df,\n",
    "        table,\n",
    "        job_config=job_config\n",
    "    )\n",
    "\n",
    "    # Wait for job completion\n",
    "    job.result()\n",
    "    \n",
    "    action = \"appended to\" if table_exists else \"loaded into new\"\n",
    "    print(f\"Successfully {action} {job.output_rows} rows to table {table.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_dataset_id = 'ErzhuoShao/SciSciGPT-SciSciNet'\n",
    "revision = 'ef5553f34410575c8cab8ad209a7b11a4253b2b6'\n",
    "project_id = 'your-gcp-project-id'\n",
    "dataset_id = 'your-bigquery-dataset-id'\n",
    "\n",
    "max_shard_num = np.inf # Should be changed to np.inf to upload the whole dataset\n",
    "\n",
    "bigquery_dataset = f'{project_id}.{dataset_id}'\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "try:\n",
    "    # Try to get the dataset\n",
    "    dataset = client.get_dataset(dataset_id)\n",
    "    print(f\"Dataset {dataset_id} already exists\")\n",
    "except NotFound:\n",
    "    # Create the dataset if it doesn't exist\n",
    "    dataset = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "    dataset.location = \"US\"  # Set location as needed\n",
    "    dataset.description = \"SciSciNet dataset replication containing papers, authors, citations and other scientific metadata\"\n",
    "    \n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print(f\"Created dataset {dataset.dataset_id}\")\n",
    "\n",
    "# Clear all existing tables in the dataset before uploading\n",
    "tables = client.list_tables(dataset_id)\n",
    "table_list = list(tables)\n",
    "print(f\"Found {len(table_list)} existing tables. Deleting...\")\n",
    "for table in table_list:\n",
    "\tclient.delete_table(table.reference)\n",
    "\tprint(f\"Deleted table: {table.table_id}\")\n",
    "print(\"All tables cleared successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define table schema based on DataFrame columns\n",
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Primary Key) Paper Unique Identifier\"),\n",
    "    SchemaField(\"doi\", \"STRING\", mode=\"NULLABLE\", description=\"Digital Object Identifier\"),\n",
    "    # Publication Info\n",
    "    SchemaField(\"doc_type\", \"STRING\", mode=\"NULLABLE\", description=\"Document type. Options include Conference, Journal, Thesis, Book, BookChapter, Repository, Dataset\"),\n",
    "    SchemaField(\"year\", \"INTEGER\", mode=\"NULLABLE\", description=\"Publication year\"),\n",
    "    SchemaField(\"date\", \"STRING\", mode=\"NULLABLE\", description=\"Publication date\"),\n",
    "    SchemaField(\"author_count\", \"INTEGER\", mode=\"NULLABLE\", description=\"Number of authors\"),\n",
    "    SchemaField(\"institution_count\", \"INTEGER\", mode=\"NULLABLE\", description=\"Number of institutions the authors are affiliated with\"),\n",
    "    # Journal & Conference\n",
    "    SchemaField(\"journal_id\", \"INTEGER\", mode=\"NULLABLE\", description=\"Journal Unique Identifier in which the paper is published, if applicable.\"),\n",
    "    SchemaField(\"journal_name\", \"STRING\", mode=\"NULLABLE\", description=\"Journal name\"),\n",
    "    SchemaField(\"journal_issn\", \"STRING\", mode=\"NULLABLE\", description=\"Journal ISSN code\"),\n",
    "    SchemaField(\"journal_publisher\", \"STRING\", mode=\"NULLABLE\", description=\"Journal publisher\"),\n",
    "    SchemaField(\"journal_url\", \"STRING\", mode=\"NULLABLE\", description=\"Journal web URL\"),\n",
    "    SchemaField(\"conference_id\", \"INTEGER\", mode=\"NULLABLE\", description=\"Conference Unique Identifier, if applicable.\"),\n",
    "    SchemaField(\"conference_name\", \"STRING\", mode=\"NULLABLE\", description=\"Conference name\"),\n",
    "    SchemaField(\"conference_abbr_name\", \"STRING\", mode=\"NULLABLE\", description=\"Conference Abbreviated name\"),\n",
    "    # Paper Metrics\n",
    "    SchemaField(\"citation_count\", \"INTEGER\", mode=\"NULLABLE\", description=\"Total number of citations received by the paper.\"),\n",
    "    SchemaField(\"citation_count_10y\", \"INTEGER\", mode=\"NULLABLE\", description=\"Number of citations received within 10 years of publication.\"),\n",
    "    SchemaField(\"citation_count_5y\", \"INTEGER\", mode=\"NULLABLE\", description=\"Number of citations received within 5 years of publication.\"),\n",
    "    SchemaField(\"reference_count\", \"INTEGER\", mode=\"NULLABLE\", description=\"Number of references cited by the paper.\"),\n",
    "    SchemaField(\"disruption_score\", \"FLOAT\", mode=\"NULLABLE\", description=\"Disruption score indicating the paper's impact in displacing prior work in its field. Its value spans from -1.0 to 1.0, with higher values indicating more disruption\"),\n",
    "    SchemaField(\"novelty_score\", \"FLOAT\", mode=\"NULLABLE\", description=\"Novelty score, based on the top 10 percentile of Z-score of reference pairs, representing the paper's atypicality in terms of knowledge combination. Lower values indicate higher novelty\"),\n",
    "    SchemaField(\"conventionality_score\", \"FLOAT\", mode=\"NULLABLE\", description=\"Conventionality score, based on the median percentile of Z-score of reference pairs, representing the paper's conventionality in terms of knowledge combination. Higher values indicate higher conventionality\"),\n",
    "    SchemaField(\"title\", \"STRING\", mode=\"NULLABLE\", description=\"Paper title\"), \n",
    "    SchemaField(\"abstract\", \"STRING\", mode=\"NULLABLE\", description=\"Paper abstract\"),\n",
    "    SchemaField(\"abstract_embedding\", \"FLOAT64\", mode=\"REPEATED\", description=\"Paper abstract embedding. A 768-dimensional dense vector, generated by the TEXT_EMBEDDING function, which captures the semantic meaning of the text.\"),\n",
    "    ]\n",
    "\n",
    "# Set table description and location\n",
    "table_id = f\"{bigquery_dataset}.papers\"  # Replace with actual project and dataset name\n",
    "table_description = \"\"\"Each paper's id, publication time, authorship, venue, title, impact metrics, title, abstract, embeddings, and many other details\"\"\"\n",
    "\n",
    "for shard_id in trange(min(max_shard_num, 100)):    \n",
    "    print(f\"Downloading shard {shard_id} from Hugging Face\")\n",
    "    df = load_dataset(\n",
    "\t\thuggingface_dataset_id, revision=revision, split=\"train\",\n",
    "\t\tdata_files=f\"papers/shard_{shard_id:02d}.parquet\"\n",
    "\t).to_pandas()\n",
    "    print(f\"Uploading shard {shard_id} to Google BigQuery\")\n",
    "    upload_to_bigquery(\n",
    "        df=df, \n",
    "        table_id=table_id, \n",
    "        schema=schema_fields if shard_id == 0 else None,  # Only provide schema for first partition\n",
    "        table_description=table_description if shard_id == 0 else None  # Only provide description for first partition\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"institution_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Primary Key) Institution Unique Identifier\"),\n",
    "    SchemaField(\"institution_name\", \"STRING\", mode=\"NULLABLE\", description=\"Institution's official name\"),\n",
    "    SchemaField(\"grid_id\", \"STRING\", mode=\"NULLABLE\", description=\"Institution's Global Research Identifier Database (GRID) ID\"),\n",
    "    SchemaField(\"url\", \"STRING\", mode=\"NULLABLE\", description=\"Institution's official webpage URL\"),\n",
    "    SchemaField(\"latitude\", \"FLOAT\", mode=\"NULLABLE\", description=\"Institution's geographical latitude\"),\n",
    "    SchemaField(\"longitude\", \"FLOAT\", mode=\"NULLABLE\", description=\"Institution's geographical longitude\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.institutions\"\n",
    "table_description = \"Each institution's id, name, webpage url, and geographical coordinate.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"institutions.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(\n",
    "    df=df,\n",
    "    table_id=table_id,\n",
    "    table_description=table_description,\n",
    "    schema=schema_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"author_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Primary Key) Author Unique Identifier\"),\n",
    "    SchemaField(\"author_name\", \"STRING\", description=\"Author's name\"),\n",
    "    SchemaField(\"author_gender\", \"STRING\", description=\"Author's gender. Options include 'male', 'female', and 'unknown'.\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.authors\"\n",
    "table_description = \"Each author's id, name and gender.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"authors.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"field_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Primary Key) A unique identifier for each field\"),\n",
    "    SchemaField(\"field_name\", \"STRING\", description=\"The name of the research field\"),\n",
    "    SchemaField(\"field_level\", \"STRING\", description=\"The level of the research field, categorizing it as either 'top' or 'sub'\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.fields\"\n",
    "table_description = \"Each research field's id, name and field level.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"fields.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"nih_project_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Primary Key) A unique identifier for each NIH project\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.nih\"\n",
    "table_description = \"Each national institutes of health (NIH) project's id.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"nih.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"nsf_award_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Primary Key) A unique identifier for each NSF funding\"),\n",
    "    SchemaField(\"date\", \"STRING\", description=\"The date of the NSF award\"),\n",
    "    SchemaField(\"title\", \"STRING\", description=\"The title of the NSF award\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.nsf\"\n",
    "table_description = \"Each national science foundation (NSF) funding's id, date and title.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"nsf.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"nct_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Primary Key) A unique identifier for each clinical trial\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.nct\"\n",
    "table_description = \"Each clinical trial's id.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"nct.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsfeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"newsfeed_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Primary Key) A unique indentifier for each newsfeed, which is also its URL\"),\n",
    "    SchemaField(\"date\", \"STRING\", description=\"The date of the newsfeed\"),\n",
    "    SchemaField(\"title\", \"STRING\", description=\"The title of the newsfeed\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.newsfeed\"\n",
    "table_description = \"Each newsfeed's id, date and title.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"newsfeed.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"tweet_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Primary Key) A unique indentifier for each tweet\"),\n",
    "    SchemaField(\"date\", \"STRING\", description=\"The date of the tweet\"),\n",
    "    SchemaField(\"url\", \"STRING\", description=\"The URL of the tweet\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.twitter\" \n",
    "table_description = \"Each tweet's id, date and URL.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"twitter.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"patent_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Primary Key) patent Unique Identifier\"),\n",
    "    SchemaField(\"type\", \"STRING\", description=\"The type of patent (e.g. utility)\"),\n",
    "    SchemaField(\"date\", \"STRING\", description=\"The date the patent was granted\"),\n",
    "    SchemaField(\"year\", \"INTEGER\", description=\"The year the patent was granted\"),\n",
    "    SchemaField(\"title\", \"STRING\", mode=\"NULLABLE\", description=\"patent title\"), \n",
    "    SchemaField(\"abstract\", \"STRING\", mode=\"NULLABLE\", description=\"patent abstract\"),\n",
    "    SchemaField(\"abstract_embedding\", \"FLOAT64\", mode=\"REPEATED\", description=\"patent abstract embedding\"),\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.patents\"\n",
    "table_description = \"Each patent's id, type, date, year.\"\n",
    "\n",
    "for shard_id in trange(min(max_shard_num, 50)):    \n",
    "    print(f\"Downloading shard {shard_id} from Hugging Face\")\n",
    "    df = load_dataset(\n",
    "\t\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\t\tdata_files=f\"patents/shard_{shard_id:02d}.parquet\"\n",
    "\t).to_pandas()\n",
    "    print(f\"Uploading shard {shard_id} to Google BigQuery\")\n",
    "    upload_to_bigquery(\n",
    "        df=df, \n",
    "        table_id=table_id, \n",
    "        schema=schema_fields if shard_id == 0 else None,  # Only provide schema for first partition\n",
    "        table_description=table_description if shard_id == 0 else None  # Only provide description for first partition\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Author Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"author_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to authors\"),\n",
    "    SchemaField(\"institution_id\", \"INTEGER\", description=\"(Foreign Key) Links to institutions\"),\n",
    "    SchemaField(\"author_order\", \"INTEGER\", mode=\"REQUIRED\", description=\"Numeric order representing the author's position in the list of authors for the paper\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_author_affiliations\"\n",
    "table_description = \"Many-to-many-to-many relationships between papers, authors, and their affiliated institutions.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_author_affiliations.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"citing_paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to citing paper\"),\n",
    "    SchemaField(\"cited_paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to cited paper\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_citations\"\n",
    "table_description = \"Many-to-many citation relationships between papers.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_citations.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"field_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to fields\"),\n",
    "    SchemaField(\"is_hit_1pct\", \"BOOLEAN\", mode=\"REQUIRED\", description=\"If the paper is in top 1% cited papers within its field and publication year\"),\n",
    "    SchemaField(\"is_hit_5pct\", \"BOOLEAN\", mode=\"REQUIRED\", description=\"If the paper is in top 5% cited papers within its field and publication year\"), \n",
    "    SchemaField(\"is_hit_10pct\", \"BOOLEAN\", mode=\"REQUIRED\", description=\"If the paper is in top 10% cited papers within its field and publication year\"),\n",
    "    SchemaField(\"normalized_citations\", \"FLOAT\", description=\"Number of citations normalized by field and year\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_fields\"\n",
    "table_description = \"Many-to-many relationships between papers and theirresearch fields.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_fields.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to cited papers\"),\n",
    "    SchemaField(\"patent_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to citing patents\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_patents\"\n",
    "table_description = \"Many-to-many relationships between papers and their patent citations.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_patents.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper NCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"nct_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to clinical trials\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_nct\"\n",
    "table_description = \"Many-to-many relationships between papers and clinical trials.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_nct.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"nih_project_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to NIH projects\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_nih\"\n",
    "table_description = \"Many-to-many relationships between papers and National Institutes of Health (NIH) projects.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_nih.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper NSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"nsf_award_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to NSF awards\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_nsf\"\n",
    "table_description = \"Many-to-many relationships between papers and National Science Foundation (NSF) awards.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_nsf.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Newsfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"newsfeed_id\", \"STRING\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to newsfeeds\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_newsfeed\"\n",
    "table_description = \"Many-to-many relationships between papers and newsfeeds.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_newsfeed.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paper Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_fields = [\n",
    "    SchemaField(\"paper_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to papers\"),\n",
    "    SchemaField(\"tweet_id\", \"INTEGER\", mode=\"REQUIRED\", description=\"(Foreign Key) Links to tweets\")\n",
    "]\n",
    "\n",
    "table_id = f\"{bigquery_dataset}.paper_twitter\"\n",
    "table_description = \"Many-to-many relationships between papers and tweets.\"\n",
    "\n",
    "df = load_dataset(\n",
    "\thuggingface_dataset_id, revision=revision, split=\"train\", \n",
    "\tdata_files=\"paper_twitter.parquet\"\n",
    ").to_pandas()\n",
    "\n",
    "upload_to_bigquery(df=df, table_id=table_id, schema=schema_fields, table_description=table_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciscigpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
